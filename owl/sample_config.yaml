#
# sample_config.yaml
#
# Copy this up one level to the root of the source tree, from where the server will be run, and
# rename to config.yaml. Change settings as needed.
#

llm:
  model: ollama/llama2
  api_base_url: http://localhost:11434
  api_key: your_llm_api_key_if_needed

captures:
  capture_dir: captures

user:
  name: "Bob"
  client_token: your_own_secret_token

vad:
  vad_model_savedir: pretrained_models/vad

deepgram:
  api_key: ""
  model: "nova-2"
  language: "en-US"

async_whisper:
  host: "127.0.0.1"
  port: 8010
  hf_token: your_hugging_face_token
  device: cpu
  compute_type: int8
  batch_size: 16
  model: tiny
  verification_threshold: 0.1
  verification_model_source: speechbrain/spkrec-ecapa-voxceleb
  verification_model_savedir: pretrained_models/spkrec-ecapa-voxceleb

streaming_whisper:
  host: "127.0.0.1"
  port: 8009
  model: "small"
  language: "en"
  silero_sensitivity: 0.4
  webrtc_sensitivity: 2
  post_speech_silence_duration: 0.5

async_transcription:
  provider: "whisper"
  #provider: "deepgram"

streaming_transcription:
  provider: "whisper"
  # provider: "deepgram"

database:
  url: "sqlite:///./db.sqlite3"

conversation_endpointing:
  timeout_seconds: 300
  min_utterances: 2

notification:
  apn_team_id: ""

# enable for LTE-M boards
udp:
  enabled: false
  host: '0.0.0.0'
  port: 8001